Image Captioning is the process of generating textual description of an image. It uses both Natural Language Processing and Computer Vision to generate the captions.
This task lies at the intersection of computer vision and natural language processing. Most image captioning systems use an encoder-decoder framework, where an input image is encoded into an intermediate representation of the information in the image, and then decoded into a descriptive text sequence.
In this project we are performing Image Captioning using Google Tensorflow, CNN ( extract the features from the image of some vector size aka the vector embeddings) 
and LSTM (For the text generation process)
In this project we are using Flickr 8K Dataset & Flickr 8K text Dataset including captions.txt file 
